{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d51af28c-45de-4cff-a3de-afced398120c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sequences: 1953it [00:31, 61.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 1953 sequences.\n",
      "Pretrained model Overall Next Token Prediction Accuracy: 0.4810 (189516/394025)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sequences: 1953it [00:32, 59.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 1953 sequences.\n",
      "Finetuned model Overall Next Token Prediction Accuracy: 0.9813 (386659/394025)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from Bio import SeqIO\n",
    "from tqdm import tqdm\n",
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "def compute_next_token_prediction_accuracy(model, tokenizer, sequence, device=torch.device(\"cpu\")):\n",
    "    \"\"\"\n",
    "    Computes next token prediction accuracy for a causal language model.\n",
    "    \n",
    "    For a given sequence, this function computes the probability distribution for the next token\n",
    "    at every position (except the first token, which has no preceding context) and compares the \n",
    "    predicted token (argmax of the model's logits) with the actual token.\n",
    "    \n",
    "    Args:\n",
    "        model: The autoregressive language model (e.g., progen2).\n",
    "        tokenizer: The corresponding tokenizer.\n",
    "        sequence: A string representing the protein (or other) sequence.\n",
    "        device: Torch device on which to run computations.\n",
    "    \n",
    "    Returns:\n",
    "        A tuple (correct, total) where:\n",
    "          - correct: number of next-token predictions that exactly match the target token.\n",
    "          - total: total number of predictions made (i.e., sequence length minus one).\n",
    "    \"\"\"\n",
    "    # Tokenize the sequence.\n",
    "    encoded = tokenizer(sequence, return_tensors=\"pt\")\n",
    "    input_ids = encoded.input_ids.to(device)\n",
    "    attention_mask = encoded.attention_mask.to(device)\n",
    "    \n",
    "    # Forward pass through the model.\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits  # shape: [batch, sequence_length, vocab_size]\n",
    "    \n",
    "    # Shift logits to compare predictions at positions 0 ... (L-2) with target tokens at 1 ... (L-1)\n",
    "    logits_shifted = logits[:, :-1, :]\n",
    "    predictions = torch.argmax(logits_shifted, dim=-1)\n",
    "    targets = input_ids[:, 1:]\n",
    "    \n",
    "    # Count correct predictions.\n",
    "    correct = (predictions == targets).sum().item()\n",
    "    total = targets.numel()  # Total number of predictions\n",
    "    \n",
    "    return correct, total\n",
    "\n",
    "# ----- Load model and tokenizer -----\n",
    "base_model_name = \"hugohrban/progen2-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name, trust_remote_code=True)\n",
    "model_pretrained = AutoModelForCausalLM.from_pretrained(base_model_name, trust_remote_code=True)\n",
    "\n",
    "adapter_checkpoint = \"/home/sdowell/scratch/Thesis/ADP1/runs/progen2_dgoa_finetune_1/checkpoint-3000\"\n",
    "model_with_adapter = AutoModelForCausalLM.from_pretrained(base_model_name, trust_remote_code=True)\n",
    "model_finetuned = PeftModel.from_pretrained(model_with_adapter, adapter_checkpoint)\n",
    "\n",
    "# ----- Set device -----\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ----- Process the entire test set from a FASTA file -----\n",
    "fasta_file = \"/home/sdowell/scratch/Thesis/ADP1/finetuning_data/test/dgoa_mutants_test.fasta\"\n",
    "\n",
    "# Process pretrained model.\n",
    "total_correct = 0\n",
    "total_predictions = 0\n",
    "n_sequences = 0\n",
    "\n",
    "for record in tqdm(SeqIO.parse(fasta_file, \"fasta\"), desc=\"Processing sequences\"):\n",
    "    seq = str(record.seq).strip()\n",
    "    if not seq:\n",
    "        continue\n",
    "    correct, predictions = compute_next_token_prediction_accuracy(model_pretrained, tokenizer, seq, device)\n",
    "    total_correct += correct\n",
    "    total_predictions += predictions\n",
    "    n_sequences += 1\n",
    "\n",
    "overall_accuracy = total_correct / total_predictions if total_predictions > 0 else 0.0\n",
    "print(f\"\\nProcessed {n_sequences} sequences.\")\n",
    "print(f\"Pretrained model Overall Next Token Prediction Accuracy: {overall_accuracy:.4f} ({total_correct}/{total_predictions})\")\n",
    "\n",
    "# Reinitialize the counters for the finetuned model.\n",
    "total_correct = 0\n",
    "total_predictions = 0\n",
    "n_sequences = 0\n",
    "\n",
    "for record in tqdm(SeqIO.parse(fasta_file, \"fasta\"), desc=\"Processing sequences\"):\n",
    "    seq = str(record.seq).strip()\n",
    "    if not seq:\n",
    "        continue\n",
    "    correct, predictions = compute_next_token_prediction_accuracy(model_finetuned, tokenizer, seq, device)\n",
    "    total_correct += correct\n",
    "    total_predictions += predictions\n",
    "    n_sequences += 1\n",
    "\n",
    "overall_accuracy = total_correct / total_predictions if total_predictions > 0 else 0.0\n",
    "print(f\"\\nProcessed {n_sequences} sequences.\")\n",
    "print(f\"Finetuned model Overall Next Token Prediction Accuracy: {overall_accuracy:.4f} ({total_correct}/{total_predictions})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34a4c05-0874-4d9f-a84e-9ad49f4fb93c",
   "metadata": {},
   "source": [
    "# ProGen2 Pre-trained Recall, Precision, F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b748d02a-f275-4c63-8f4c-6977a68a38e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sequences: 1953it [00:28, 67.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2  0.0000000000 0.0000000000 0.0000000000         0\n",
      "           A  0.4206917287 0.6628715519 0.5147176618     65435\n",
      "           C  0.0033149171 0.0003905741 0.0006988120      7681\n",
      "           D  0.2133455112 0.2425334392 0.2270050877     16373\n",
      "           E  0.4952723399 0.5689154046 0.5295457782     19611\n",
      "           F  0.3915498639 0.3122386619 0.3474254015     12436\n",
      "           G  0.8263081210 0.8742663962 0.8496110177     36975\n",
      "           H  0.0373134328 0.0041701418 0.0075018755      3597\n",
      "           I  0.5933415754 0.2468677665 0.3486676526     27217\n",
      "           K  0.5085600734 0.2262341901 0.3131588855     14706\n",
      "           L  0.3394532064 0.6190370605 0.4384689596     31570\n",
      "           M  0.0720000000 0.0485118350 0.0579669560      4267\n",
      "           N  0.8333583998 0.6924518870 0.7563988806      8002\n",
      "           P  0.6292978709 0.6924709986 0.6593747744     26378\n",
      "           Q  0.2712440517 0.0362068966 0.0638859979     22040\n",
      "           R  0.2246840637 0.2957655192 0.2553707446     13886\n",
      "           S  0.5535535536 0.3904615187 0.4579193014     15579\n",
      "           T  0.8233350025 0.4444024001 0.5772363432     18499\n",
      "           V  0.5173503441 0.4970350404 0.5069892629     35245\n",
      "           W  0.0203442879 0.0044719642 0.0073322053      5814\n",
      "           X  0.0909090909 0.0506329114 0.0650406504        79\n",
      "           Y  0.5549843260 0.5125651419 0.5329319687      8635\n",
      "\n",
      "    accuracy                      0.4809745575    394025\n",
      "   macro avg  0.3827368982 0.3373864227 0.3416931008    394025\n",
      "weighted avg  0.4830657958 0.4809745575 0.4580035512    394025\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def compute_token_level_metrics(model, tokenizer, sequence, device=torch.device(\"cpu\")):\n",
    "    encoded = tokenizer(sequence, return_tensors=\"pt\")\n",
    "    input_ids = encoded.input_ids.to(device)\n",
    "    attention_mask = encoded.attention_mask.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "\n",
    "    logits_shifted = logits[:, :-1, :]\n",
    "    predictions = torch.argmax(logits_shifted, dim=-1)\n",
    "    targets = input_ids[:, 1:]\n",
    "\n",
    "    preds = predictions.view(-1).tolist()\n",
    "    trues = targets.view(-1).tolist()\n",
    "\n",
    "    return trues, preds\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "all_trues = []\n",
    "all_preds = []\n",
    "\n",
    "for record in tqdm(SeqIO.parse(fasta_file, \"fasta\"), desc=\"Processing sequences\"):\n",
    "    seq = str(record.seq).strip()\n",
    "    if not seq:\n",
    "        continue\n",
    "    trues, preds = compute_token_level_metrics(model_pretrained, tokenizer, seq, device)\n",
    "    all_trues.extend(trues)\n",
    "    all_preds.extend(preds)\n",
    "\n",
    "# Convert token IDs back to tokens (optional but makes report readable)\n",
    "id2token = tokenizer.convert_ids_to_tokens\n",
    "\n",
    "true_tokens = [id2token(t) for t in all_trues]\n",
    "pred_tokens = [id2token(p) for p in all_preds]\n",
    "\n",
    "print(classification_report(true_tokens, pred_tokens, zero_division=0, digits=10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc51981-d89e-4f98-8a61-25673a0a2889",
   "metadata": {},
   "source": [
    "# ProGen2 fine-tuned Recall, Precisio, F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e472cbb3-2420-4028-bc07-4a29c9910440",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sequences: 1953it [00:29, 65.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A  0.9842795954 0.9903415603 0.9873012729     65435\n",
      "           C  0.9963432154 0.9932300482 0.9947841961      7681\n",
      "           D  0.9522445081 0.9742869358 0.9631396226     16373\n",
      "           E  0.9834345952 0.9656825251 0.9744777195     19611\n",
      "           F  0.9583992407 0.9744290769 0.9663476874     12436\n",
      "           G  0.9935012404 0.9964300203 0.9949634751     36975\n",
      "           H  0.9904640814 0.8662774534 0.9242177073      3597\n",
      "           I  0.9902736014 0.9800859757 0.9851534513     27217\n",
      "           K  0.9321231255 0.9636882905 0.9476429288     14706\n",
      "           L  0.9958693442 0.9927779538 0.9943212462     31570\n",
      "           M  0.9881460408 0.9767986876 0.9824395993      4267\n",
      "           N  0.9886540916 0.8711572107 0.9261941141      8002\n",
      "           P  0.9885978776 0.9959435894 0.9922571385     26378\n",
      "           Q  0.9651863914 0.9950090744 0.9798708697     22040\n",
      "           R  0.9901232788 0.9890537232 0.9895882120     13886\n",
      "           S  0.9860084995 0.9680338918 0.9769385243     15579\n",
      "           T  0.9736926532 0.9843775339 0.9790059407     18499\n",
      "           V  0.9764447862 0.9726769755 0.9745572391     35245\n",
      "           W  0.9960447120 0.9962160303 0.9961303637      5814\n",
      "           X  0.8653846154 0.5696202532 0.6870229008        79\n",
      "           Y  0.9954787851 0.9944412276 0.9949597358      8635\n",
      "\n",
      "    accuracy                      0.9813057547    394025\n",
      "   macro avg  0.9757473466 0.9528837161 0.9624435212    394025\n",
      "weighted avg  0.9814659824 0.9813057547 0.9812225601    394025\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "all_trues = []\n",
    "all_preds = []\n",
    "\n",
    "for record in tqdm(SeqIO.parse(fasta_file, \"fasta\"), desc=\"Processing sequences\"):\n",
    "    seq = str(record.seq).strip()\n",
    "    if not seq:\n",
    "        continue\n",
    "    trues, preds = compute_token_level_metrics(model_finetuned, tokenizer, seq, device)\n",
    "    all_trues.extend(trues)\n",
    "    all_preds.extend(preds)\n",
    "\n",
    "# Convert token IDs back to tokens (optional but makes report readable)\n",
    "id2token = tokenizer.convert_ids_to_tokens\n",
    "\n",
    "true_tokens = [id2token(t) for t in all_trues]\n",
    "pred_tokens = [id2token(p) for p in all_preds]\n",
    "\n",
    "print(classification_report(true_tokens, pred_tokens, zero_division=0, digits=10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e816bb24-ed72-442c-97dc-5d05e50fa2b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
