2025-03-22 19:32:31,254 INFO: Training configuration saved to runs/esm_8m_ecoli_finetuning_1/train_config.yaml
2025-03-22 19:32:32,905 INFO: Found potential target modules: ['esm.encoder.layer.0.attention.self.key', 'esm.encoder.layer.0.attention.self.value', 'esm.encoder.layer.1.attention.self.key', 'esm.encoder.layer.1.attention.self.value', 'esm.encoder.layer.2.attention.self.key', 'esm.encoder.layer.2.attention.self.value', 'esm.encoder.layer.3.attention.self.key', 'esm.encoder.layer.3.attention.self.value', 'esm.encoder.layer.4.attention.self.key', 'esm.encoder.layer.4.attention.self.value', 'esm.encoder.layer.5.attention.self.key', 'esm.encoder.layer.5.attention.self.value', 'esm.encoder.layer.6.attention.self.key', 'esm.encoder.layer.6.attention.self.value', 'esm.encoder.layer.7.attention.self.key', 'esm.encoder.layer.7.attention.self.value', 'esm.encoder.layer.8.attention.self.key', 'esm.encoder.layer.8.attention.self.value', 'esm.encoder.layer.9.attention.self.key', 'esm.encoder.layer.9.attention.self.value', 'esm.encoder.layer.10.attention.self.key', 'esm.encoder.layer.10.attention.self.value', 'esm.encoder.layer.11.attention.self.key', 'esm.encoder.layer.11.attention.self.value', 'esm.encoder.layer.12.attention.self.key', 'esm.encoder.layer.12.attention.self.value', 'esm.encoder.layer.13.attention.self.key', 'esm.encoder.layer.13.attention.self.value', 'esm.encoder.layer.14.attention.self.key', 'esm.encoder.layer.14.attention.self.value', 'esm.encoder.layer.15.attention.self.key', 'esm.encoder.layer.15.attention.self.value', 'esm.encoder.layer.16.attention.self.key', 'esm.encoder.layer.16.attention.self.value', 'esm.encoder.layer.17.attention.self.key', 'esm.encoder.layer.17.attention.self.value', 'esm.encoder.layer.18.attention.self.key', 'esm.encoder.layer.18.attention.self.value', 'esm.encoder.layer.19.attention.self.key', 'esm.encoder.layer.19.attention.self.value', 'esm.encoder.layer.20.attention.self.key', 'esm.encoder.layer.20.attention.self.value', 'esm.encoder.layer.21.attention.self.key', 'esm.encoder.layer.21.attention.self.value', 'esm.encoder.layer.22.attention.self.key', 'esm.encoder.layer.22.attention.self.value', 'esm.encoder.layer.23.attention.self.key', 'esm.encoder.layer.23.attention.self.value', 'esm.encoder.layer.24.attention.self.key', 'esm.encoder.layer.24.attention.self.value', 'esm.encoder.layer.25.attention.self.key', 'esm.encoder.layer.25.attention.self.value', 'esm.encoder.layer.26.attention.self.key', 'esm.encoder.layer.26.attention.self.value', 'esm.encoder.layer.27.attention.self.key', 'esm.encoder.layer.27.attention.self.value', 'esm.encoder.layer.28.attention.self.key', 'esm.encoder.layer.28.attention.self.value', 'esm.encoder.layer.29.attention.self.key', 'esm.encoder.layer.29.attention.self.value']
2025-03-22 19:32:32,905 INFO: Using target module names: ['key', 'value']
2025-03-22 19:32:32,906 INFO: Parameters requiring gradients before LoRA: 148796794
2025-03-22 19:32:32,976 INFO: Trainable parameter: base_model.model.esm.encoder.layer.0.attention.self.key.lora_A.default.weight (shape: torch.Size([8, 640]))
2025-03-22 19:32:32,977 INFO: Trainable parameter: base_model.model.esm.encoder.layer.0.attention.self.key.lora_B.default.weight (shape: torch.Size([640, 8]))
2025-03-22 19:32:32,977 INFO: Trainable parameter: base_model.model.esm.encoder.layer.0.attention.self.value.lora_A.default.weight (shape: torch.Size([8, 640]))
2025-03-22 19:32:32,977 INFO: Trainable parameter: base_model.model.esm.encoder.layer.0.attention.self.value.lora_B.default.weight (shape: torch.Size([640, 8]))
2025-03-22 19:32:32,977 INFO: Trainable parameter: base_model.model.esm.encoder.layer.1.attention.self.key.lora_A.default.weight (shape: torch.Size([8, 640]))
2025-03-22 19:32:32,977 INFO: Trainable parameter: base_model.model.esm.encoder.layer.1.attention.self.key.lora_B.default.weight (shape: torch.Size([640, 8]))
2025-03-22 19:32:32,978 INFO: Trainable parameter: base_model.model.esm.encoder.layer.1.attention.self.value.lora_A.default.weight (shape: torch.Size([8, 640]))
2025-03-22 19:32:32,978 INFO: Trainable parameter: base_model.model.esm.encoder.layer.1.attention.self.value.lora_B.default.weight (shape: torch.Size([640, 8]))
2025-03-22 19:32:32,978 INFO: Trainable parameter: base_model.model.esm.encoder.layer.2.attention.self.key.lora_A.default.weight (shape: torch.Size([8, 640]))
2025-03-22 19:32:32,978 INFO: Trainable parameter: base_model.model.esm.encoder.layer.2.attention.self.key.lora_B.default.weight (shape: torch.Size([640, 8]))
2025-03-22 19:32:32,978 INFO: Trainable parameter: base_model.model.esm.encoder.layer.2.attention.self.value.lora_A.default.weight (shape: torch.Size([8, 640]))
2025-03-22 19:32:32,978 INFO: Trainable parameter: base_model.model.esm.encoder.layer.2.attention.self.value.lora_B.default.weight (shape: torch.Size([640, 8]))
2025-03-22 19:32:32,978 INFO: Trainable parameter: base_model.model.esm.encoder.layer.3.attention.self.key.lora_A.default.weight (shape: torch.Size([8, 640]))
2025-03-22 19:32:32,978 INFO: Trainable parameter: base_model.model.esm.encoder.layer.3.attention.self.key.lora_B.default.weight (shape: torch.Size([640, 8]))
2025-03-22 19:32:32,978 INFO: Trainable parameter: base_model.model.esm.encoder.layer.3.attention.self.value.lora_A.default.weight (shape: torch.Size([8, 640]))
2025-03-22 19:32:32,978 INFO: Trainable parameter: base_model.model.esm.encoder.layer.3.attention.self.value.lora_B.default.weight (shape: torch.Size([640, 8]))
2025-03-22 19:32:32,979 INFO: Trainable parameter: base_model.model.esm.encoder.layer.4.attention.self.key.lora_A.default.weight (shape: torch.Size([8, 640]))
2025-03-22 19:32:32,979 INFO: Trainable parameter: base_model.model.esm.encoder.layer.4.attention.self.key.lora_B.default.weight (shape: torch.Size([640, 8]))
2025-03-22 19:32:32,979 INFO: Trainable parameter: base_model.model.esm.encoder.layer.4.attention.self.value.lora_A.default.weight (shape: torch.Size([8, 640]))
2025-03-22 19:32:32,979 INFO: Trainable parameter: base_model.model.esm.encoder.layer.4.attention.self.value.lora_B.default.weight (shape: torch.Size([640, 8]))
2025-03-22 19:32:32,979 INFO: Trainable parameter: base_model.model.esm.encoder.layer.5.attention.self.key.lora_A.default.weight (shape: torch.Size([8, 640]))
2025-03-22 19:32:32,979 INFO: Trainable parameter: base_model.model.esm.encoder.layer.5.attention.self.key.lora_B.default.weight (shape: torch.Size([640, 8]))
2025-03-22 19:32:32,979 INFO: Trainable parameter: base_model.model.esm.encoder.layer.5.attention.self.value.lora_A.default.weight (shape: torch.Size([8, 640]))
2025-03-22 19:32:32,979 INFO: Trainable parameter: base_model.model.esm.encoder.layer.5.attention.self.value.lora_B.default.weight (shape: torch.Size([640, 8]))
2025-03-22 19:32:32,979 INFO: Trainable parameter: base_model.model.esm.encoder.layer.6.attention.self.key.lora_A.default.weight (shape: torch.Size([8, 640]))
2025-03-22 19:32:32,979 INFO: Trainable parameter: base_model.model.esm.encoder.layer.6.attention.self.key.lora_B.default.weight (shape: torch.Size([640, 8]))
2025-03-22 19:32:32,979 INFO: Trainable parameter: base_model.model.esm.encoder.layer.6.attention.self.value.lora_A.default.weight (shape: torch.Size([8, 640]))
2025-03-22 19:32:32,979 INFO: Trainable parameter: base_model.model.esm.encoder.layer.6.attention.self.value.lora_B.default.weight (shape: torch.Size([640, 8]))
2025-03-22 19:32:32,980 INFO: Trainable parameter: base_model.model.esm.encoder.layer.7.attention.self.key.lora_A.default.weight (shape: torch.Size([8, 640]))
2025-03-22 19:32:32,980 INFO: Trainable parameter: base_model.model.esm.encoder.layer.7.attention.self.key.lora_B.default.weight (shape: torch.Size([640, 8]))
2025-03-22 19:32:32,980 INFO: Trainable parameter: base_model.model.esm.encoder.layer.7.attention.self.value.lora_A.default.weight (shape: torch.Size([8, 640]))
2025-03-22 19:32:32,980 INFO: Trainable parameter: base_model.model.esm.encoder.layer.7.attention.self.value.lora_B.default.weight (shape: torch.Size([640, 8]))
2025-03-22 19:32:32,980 INFO: Trainable parameter: base_model.model.esm.encoder.layer.8.attention.self.key.lora_A.default.weight (shape: torch.Size([8, 640]))
2025-03-22 19:32:32,980 INFO: Trainable parameter: base_model.model.esm.encoder.layer.8.attention.self.key.lora_B.default.weight (shape: torch.Size([640, 8]))
2025-03-22 19:32:32,980 INFO: Trainable parameter: base_model.model.esm.encoder.layer.8.attention.self.value.lora_A.default.weight (shape: torch.Size([8, 640]))
2025-03-22 19:32:32,980 INFO: Trainable parameter: base_model.model.esm.encoder.layer.8.attention.self.value.lora_B.default.weight (shape: torch.Size([640, 8]))
2025-03-22 19:32:32,980 INFO: Trainable parameter: base_model.model.esm.encoder.layer.9.attention.self.key.lora_A.default.weight (shape: torch.Size([8, 640]))
2025-03-22 19:32:32,980 INFO: Trainable parameter: base_model.model.esm.encoder.layer.9.attention.self.key.lora_B.default.weight (shape: torch.Size([640, 8]))
2025-03-22 19:32:32,980 INFO: Trainable parameter: base_model.model.esm.encoder.layer.9.attention.self.value.lora_A.default.weight (shape: torch.Size([8, 640]))
2025-03-22 19:32:32,981 INFO: Trainable parameter: base_model.model.esm.encoder.layer.9.attention.self.value.lora_B.default.weight (shape: torch.Size([640, 8]))
2025-03-22 19:32:32,981 INFO: Trainable parameter: base_model.model.esm.encoder.layer.10.attention.self.key.lora_A.default.weight (shape: torch.Size([8, 640]))
2025-03-22 19:32:32,981 INFO: Trainable parameter: base_model.model.esm.encoder.layer.10.attention.self.key.lora_B.default.weight (shape: torch.Size([640, 8]))
2025-03-22 19:32:32,981 INFO: Trainable parameter: base_model.model.esm.encoder.layer.10.attention.self.value.lora_A.default.weight (shape: torch.Size([8, 640]))
2025-03-22 19:32:32,981 INFO: Trainable parameter: base_model.model.esm.encoder.layer.10.attention.self.value.lora_B.default.weight (shape: torch.Size([640, 8]))
2025-03-22 19:32:32,981 INFO: Trainable parameter: base_model.model.esm.encoder.layer.11.attention.self.key.lora_A.default.weight (shape: torch.Size([8, 640]))
2025-03-22 19:32:32,981 INFO: Trainable parameter: base_model.model.esm.encoder.layer.11.attention.self.key.lora_B.default.weight (shape: torch.Size([640, 8]))
2025-03-22 19:32:32,981 INFO: Trainable parameter: base_model.model.esm.encoder.layer.11.attention.self.value.lora_A.default.weight (shape: torch.Size([8, 640]))
2025-03-22 19:32:32,981 INFO: Trainable parameter: base_model.model.esm.encoder.layer.11.attention.self.value.lora_B.default.weight (shape: torch.Size([640, 8]))
2025-03-22 19:32:32,982 INFO: Trainable parameter: base_model.model.esm.encoder.layer.12.attention.self.key.lora_A.default.weight (shape: torch.Size([8, 640]))
2025-03-22 19:32:32,982 INFO: Trainable parameter: base_model.model.esm.encoder.layer.12.attention.self.key.lora_B.default.weight (shape: torch.Size([640, 8]))
2025-03-22 19:32:32,982 INFO: Trainable parameter: base_model.model.esm.encoder.layer.12.attention.self.value.lora_A.default.weight (shape: torch.Size([8, 640]))
2025-03-22 19:32:32,982 INFO: Trainable parameter: base_model.model.esm.encoder.layer.12.attention.self.value.lora_B.default.weight (shape: torch.Size([640, 8]))
2025-03-22 19:32:32,982 INFO: Trainable parameter: base_model.model.esm.encoder.layer.13.attention.self.key.lora_A.default.weight (shape: torch.Size([8, 640]))
2025-03-22 19:32:32,982 INFO: Trainable parameter: base_model.model.esm.encoder.layer.13.attention.self.key.lora_B.default.weight (shape: torch.Size([640, 8]))
2025-03-22 19:32:32,982 INFO: Trainable parameter: base_model.model.esm.encoder.layer.13.attention.self.value.lora_A.default.weight (shape: torch.Size([8, 640]))
2025-03-22 19:32:32,982 INFO: Trainable parameter: base_model.model.esm.encoder.layer.13.attention.self.value.lora_B.default.weight (shape: torch.Size([640, 8]))
2025-03-22 19:32:32,982 INFO: Trainable parameter: base_model.model.esm.encoder.layer.14.attention.self.key.lora_A.default.weight (shape: torch.Size([8, 640]))
2025-03-22 19:32:32,982 INFO: Trainable parameter: base_model.model.esm.encoder.layer.14.attention.self.key.lora_B.default.weight (shape: torch.Size([640, 8]))
2025-03-22 19:32:32,983 INFO: Trainable parameter: base_model.model.esm.encoder.layer.14.attention.self.value.lora_A.default.weight (shape: torch.Size([8, 640]))
2025-03-22 19:32:32,983 INFO: Trainable parameter: base_model.model.esm.encoder.layer.14.attention.self.value.lora_B.default.weight (shape: torch.Size([640, 8]))
2025-03-22 19:32:32,983 INFO: Trainable parameter: base_model.model.esm.encoder.layer.15.attention.self.key.lora_A.default.weight (shape: torch.Size([8, 640]))
2025-03-22 19:32:32,983 INFO: Trainable parameter: base_model.model.esm.encoder.layer.15.attention.self.key.lora_B.default.weight (shape: torch.Size([640, 8]))
2025-03-22 19:32:32,983 INFO: Trainable parameter: base_model.model.esm.encoder.layer.15.attention.self.value.lora_A.default.weight (shape: torch.Size([8, 640]))
2025-03-22 19:32:32,983 INFO: Trainable parameter: base_model.model.esm.encoder.layer.15.attention.self.value.lora_B.default.weight (shape: torch.Size([640, 8]))
2025-03-22 19:32:32,983 INFO: Trainable parameter: base_model.model.esm.encoder.layer.16.attention.self.key.lora_A.default.weight (shape: torch.Size([8, 640]))
2025-03-22 19:32:32,983 INFO: Trainable parameter: base_model.model.esm.encoder.layer.16.attention.self.key.lora_B.default.weight (shape: torch.Size([640, 8]))
2025-03-22 19:32:32,983 INFO: Trainable parameter: base_model.model.esm.encoder.layer.16.attention.self.value.lora_A.default.weight (shape: torch.Size([8, 640]))
2025-03-22 19:32:32,983 INFO: Trainable parameter: base_model.model.esm.encoder.layer.16.attention.self.value.lora_B.default.weight (shape: torch.Size([640, 8]))
2025-03-22 19:32:32,984 INFO: Trainable parameter: base_model.model.esm.encoder.layer.17.attention.self.key.lora_A.default.weight (shape: torch.Size([8, 640]))
2025-03-22 19:32:32,984 INFO: Trainable parameter: base_model.model.esm.encoder.layer.17.attention.self.key.lora_B.default.weight (shape: torch.Size([640, 8]))
2025-03-22 19:32:32,984 INFO: Trainable parameter: base_model.model.esm.encoder.layer.17.attention.self.value.lora_A.default.weight (shape: torch.Size([8, 640]))
2025-03-22 19:32:32,984 INFO: Trainable parameter: base_model.model.esm.encoder.layer.17.attention.self.value.lora_B.default.weight (shape: torch.Size([640, 8]))
2025-03-22 19:32:32,984 INFO: Trainable parameter: base_model.model.esm.encoder.layer.18.attention.self.key.lora_A.default.weight (shape: torch.Size([8, 640]))
2025-03-22 19:32:32,984 INFO: Trainable parameter: base_model.model.esm.encoder.layer.18.attention.self.key.lora_B.default.weight (shape: torch.Size([640, 8]))
2025-03-22 19:32:32,984 INFO: Trainable parameter: base_model.model.esm.encoder.layer.18.attention.self.value.lora_A.default.weight (shape: torch.Size([8, 640]))
2025-03-22 19:32:32,984 INFO: Trainable parameter: base_model.model.esm.encoder.layer.18.attention.self.value.lora_B.default.weight (shape: torch.Size([640, 8]))
2025-03-22 19:32:32,984 INFO: Trainable parameter: base_model.model.esm.encoder.layer.19.attention.self.key.lora_A.default.weight (shape: torch.Size([8, 640]))
2025-03-22 19:32:32,985 INFO: Trainable parameter: base_model.model.esm.encoder.layer.19.attention.self.key.lora_B.default.weight (shape: torch.Size([640, 8]))
2025-03-22 19:32:32,985 INFO: Trainable parameter: base_model.model.esm.encoder.layer.19.attention.self.value.lora_A.default.weight (shape: torch.Size([8, 640]))
2025-03-22 19:32:32,985 INFO: Trainable parameter: base_model.model.esm.encoder.layer.19.attention.self.value.lora_B.default.weight (shape: torch.Size([640, 8]))
2025-03-22 19:32:32,985 INFO: Trainable parameter: base_model.model.esm.encoder.layer.20.attention.self.key.lora_A.default.weight (shape: torch.Size([8, 640]))
2025-03-22 19:32:32,985 INFO: Trainable parameter: base_model.model.esm.encoder.layer.20.attention.self.key.lora_B.default.weight (shape: torch.Size([640, 8]))
2025-03-22 19:32:32,985 INFO: Trainable parameter: base_model.model.esm.encoder.layer.20.attention.self.value.lora_A.default.weight (shape: torch.Size([8, 640]))
2025-03-22 19:32:32,985 INFO: Trainable parameter: base_model.model.esm.encoder.layer.20.attention.self.value.lora_B.default.weight (shape: torch.Size([640, 8]))
2025-03-22 19:32:32,985 INFO: Trainable parameter: base_model.model.esm.encoder.layer.21.attention.self.key.lora_A.default.weight (shape: torch.Size([8, 640]))
2025-03-22 19:32:32,985 INFO: Trainable parameter: base_model.model.esm.encoder.layer.21.attention.self.key.lora_B.default.weight (shape: torch.Size([640, 8]))
2025-03-22 19:32:32,985 INFO: Trainable parameter: base_model.model.esm.encoder.layer.21.attention.self.value.lora_A.default.weight (shape: torch.Size([8, 640]))
2025-03-22 19:32:32,986 INFO: Trainable parameter: base_model.model.esm.encoder.layer.21.attention.self.value.lora_B.default.weight (shape: torch.Size([640, 8]))
2025-03-22 19:32:32,986 INFO: Trainable parameter: base_model.model.esm.encoder.layer.22.attention.self.key.lora_A.default.weight (shape: torch.Size([8, 640]))
2025-03-22 19:32:32,986 INFO: Trainable parameter: base_model.model.esm.encoder.layer.22.attention.self.key.lora_B.default.weight (shape: torch.Size([640, 8]))
2025-03-22 19:32:32,986 INFO: Trainable parameter: base_model.model.esm.encoder.layer.22.attention.self.value.lora_A.default.weight (shape: torch.Size([8, 640]))
2025-03-22 19:32:32,986 INFO: Trainable parameter: base_model.model.esm.encoder.layer.22.attention.self.value.lora_B.default.weight (shape: torch.Size([640, 8]))
2025-03-22 19:32:32,986 INFO: Trainable parameter: base_model.model.esm.encoder.layer.23.attention.self.key.lora_A.default.weight (shape: torch.Size([8, 640]))
2025-03-22 19:32:32,986 INFO: Trainable parameter: base_model.model.esm.encoder.layer.23.attention.self.key.lora_B.default.weight (shape: torch.Size([640, 8]))
2025-03-22 19:32:32,986 INFO: Trainable parameter: base_model.model.esm.encoder.layer.23.attention.self.value.lora_A.default.weight (shape: torch.Size([8, 640]))
2025-03-22 19:32:32,986 INFO: Trainable parameter: base_model.model.esm.encoder.layer.23.attention.self.value.lora_B.default.weight (shape: torch.Size([640, 8]))
2025-03-22 19:32:32,986 INFO: Trainable parameter: base_model.model.esm.encoder.layer.24.attention.self.key.lora_A.default.weight (shape: torch.Size([8, 640]))
2025-03-22 19:32:32,987 INFO: Trainable parameter: base_model.model.esm.encoder.layer.24.attention.self.key.lora_B.default.weight (shape: torch.Size([640, 8]))
2025-03-22 19:32:32,987 INFO: Trainable parameter: base_model.model.esm.encoder.layer.24.attention.self.value.lora_A.default.weight (shape: torch.Size([8, 640]))
2025-03-22 19:32:32,987 INFO: Trainable parameter: base_model.model.esm.encoder.layer.24.attention.self.value.lora_B.default.weight (shape: torch.Size([640, 8]))
2025-03-22 19:32:32,987 INFO: Trainable parameter: base_model.model.esm.encoder.layer.25.attention.self.key.lora_A.default.weight (shape: torch.Size([8, 640]))
2025-03-22 19:32:32,987 INFO: Trainable parameter: base_model.model.esm.encoder.layer.25.attention.self.key.lora_B.default.weight (shape: torch.Size([640, 8]))
2025-03-22 19:32:32,987 INFO: Trainable parameter: base_model.model.esm.encoder.layer.25.attention.self.value.lora_A.default.weight (shape: torch.Size([8, 640]))
2025-03-22 19:32:32,987 INFO: Trainable parameter: base_model.model.esm.encoder.layer.25.attention.self.value.lora_B.default.weight (shape: torch.Size([640, 8]))
2025-03-22 19:32:32,987 INFO: Trainable parameter: base_model.model.esm.encoder.layer.26.attention.self.key.lora_A.default.weight (shape: torch.Size([8, 640]))
2025-03-22 19:32:32,987 INFO: Trainable parameter: base_model.model.esm.encoder.layer.26.attention.self.key.lora_B.default.weight (shape: torch.Size([640, 8]))
2025-03-22 19:32:32,988 INFO: Trainable parameter: base_model.model.esm.encoder.layer.26.attention.self.value.lora_A.default.weight (shape: torch.Size([8, 640]))
2025-03-22 19:32:32,988 INFO: Trainable parameter: base_model.model.esm.encoder.layer.26.attention.self.value.lora_B.default.weight (shape: torch.Size([640, 8]))
2025-03-22 19:32:32,988 INFO: Trainable parameter: base_model.model.esm.encoder.layer.27.attention.self.key.lora_A.default.weight (shape: torch.Size([8, 640]))
2025-03-22 19:32:32,988 INFO: Trainable parameter: base_model.model.esm.encoder.layer.27.attention.self.key.lora_B.default.weight (shape: torch.Size([640, 8]))
2025-03-22 19:32:32,988 INFO: Trainable parameter: base_model.model.esm.encoder.layer.27.attention.self.value.lora_A.default.weight (shape: torch.Size([8, 640]))
2025-03-22 19:32:32,988 INFO: Trainable parameter: base_model.model.esm.encoder.layer.27.attention.self.value.lora_B.default.weight (shape: torch.Size([640, 8]))
2025-03-22 19:32:32,988 INFO: Trainable parameter: base_model.model.esm.encoder.layer.28.attention.self.key.lora_A.default.weight (shape: torch.Size([8, 640]))
2025-03-22 19:32:32,988 INFO: Trainable parameter: base_model.model.esm.encoder.layer.28.attention.self.key.lora_B.default.weight (shape: torch.Size([640, 8]))
2025-03-22 19:32:32,988 INFO: Trainable parameter: base_model.model.esm.encoder.layer.28.attention.self.value.lora_A.default.weight (shape: torch.Size([8, 640]))
2025-03-22 19:32:32,988 INFO: Trainable parameter: base_model.model.esm.encoder.layer.28.attention.self.value.lora_B.default.weight (shape: torch.Size([640, 8]))
2025-03-22 19:32:32,988 INFO: Trainable parameter: base_model.model.esm.encoder.layer.29.attention.self.key.lora_A.default.weight (shape: torch.Size([8, 640]))
2025-03-22 19:32:32,989 INFO: Trainable parameter: base_model.model.esm.encoder.layer.29.attention.self.key.lora_B.default.weight (shape: torch.Size([640, 8]))
2025-03-22 19:32:32,989 INFO: Trainable parameter: base_model.model.esm.encoder.layer.29.attention.self.value.lora_A.default.weight (shape: torch.Size([8, 640]))
2025-03-22 19:32:32,989 INFO: Trainable parameter: base_model.model.esm.encoder.layer.29.attention.self.value.lora_B.default.weight (shape: torch.Size([640, 8]))
2025-03-22 19:32:32,989 INFO: Trainable parameter: base_model.model.lm_head.original_module.bias (shape: torch.Size([33]))
2025-03-22 19:32:32,989 INFO: Trainable parameter: base_model.model.lm_head.original_module.dense.weight (shape: torch.Size([640, 640]))
2025-03-22 19:32:32,989 INFO: Trainable parameter: base_model.model.lm_head.original_module.dense.bias (shape: torch.Size([640]))
2025-03-22 19:32:32,989 INFO: Trainable parameter: base_model.model.lm_head.original_module.layer_norm.weight (shape: torch.Size([640]))
2025-03-22 19:32:32,989 INFO: Trainable parameter: base_model.model.lm_head.original_module.layer_norm.bias (shape: torch.Size([640]))
2025-03-22 19:32:32,989 INFO: Trainable parameter: base_model.model.lm_head.modules_to_save.default.bias (shape: torch.Size([33]))
2025-03-22 19:32:32,989 INFO: Trainable parameter: base_model.model.lm_head.modules_to_save.default.dense.weight (shape: torch.Size([640, 640]))
2025-03-22 19:32:32,989 INFO: Trainable parameter: base_model.model.lm_head.modules_to_save.default.dense.bias (shape: torch.Size([640]))
2025-03-22 19:32:32,989 INFO: Trainable parameter: base_model.model.lm_head.modules_to_save.default.layer_norm.weight (shape: torch.Size([640]))
2025-03-22 19:32:32,989 INFO: Trainable parameter: base_model.model.lm_head.modules_to_save.default.layer_norm.bias (shape: torch.Size([640]))
2025-03-22 19:32:32,990 INFO: Trainable parameter: base_model.model.lm_head.modules_to_save.default.decoder.weight (shape: torch.Size([33, 640]))
2025-03-22 19:32:32,992 INFO: LoRA integration complete. Trainable parameters: 1458626 (0.97% of total)
2025-03-22 19:32:33,028 INFO: Loaded 7489 training and 1404 evaluation sequences.
2025-03-22 19:32:33,028 INFO: Adjusted max_length to 1024 to be a multiple of 8
2025-03-22 19:32:33,028 INFO: Using masked language modeling (MLM) data collator for ESM model.
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
2025-03-22 19:32:37,019 INFO: Resuming training from checkpoint: runs/esm_8m_ecoli_finetuning_1/checkpoint-3500
There were missing keys in the checkpoint model loaded: ['base_model.model.esm.embeddings.word_embeddings.weight', 'base_model.model.esm.embeddings.position_embeddings.weight', 'base_model.model.esm.encoder.layer.0.attention.self.query.weight', 'base_model.model.esm.encoder.layer.0.attention.self.query.bias', 'base_model.model.esm.encoder.layer.0.attention.self.key.base_layer.weight', 'base_model.model.esm.encoder.layer.0.attention.self.key.base_layer.bias', 'base_model.model.esm.encoder.layer.0.attention.self.key.lora_A.default.weight', 'base_model.model.esm.encoder.layer.0.attention.self.key.lora_B.default.weight', 'base_model.model.esm.encoder.layer.0.attention.self.value.base_layer.weight', 'base_model.model.esm.encoder.layer.0.attention.self.value.base_layer.bias', 'base_model.model.esm.encoder.layer.0.attention.self.value.lora_A.default.weight', 'base_model.model.esm.encoder.layer.0.attention.self.value.lora_B.default.weight', 'base_model.model.esm.encoder.layer.0.attention.self.rotary_embeddings.inv_freq', 'base_model.model.esm.encoder.layer.0.attention.output.dense.weight', 'base_model.model.esm.encoder.layer.0.attention.output.dense.bias', 'base_model.model.esm.encoder.layer.0.attention.LayerNorm.weight', 'base_model.model.esm.encoder.layer.0.attention.LayerNorm.bias', 'base_model.model.esm.encoder.layer.0.intermediate.dense.weight', 'base_model.model.esm.encoder.layer.0.intermediate.dense.bias', 'base_model.model.esm.encoder.layer.0.output.dense.weight', 'base_model.model.esm.encoder.layer.0.output.dense.bias', 'base_model.model.esm.encoder.layer.0.LayerNorm.weight', 'base_model.model.esm.encoder.layer.0.LayerNorm.bias', 'base_model.model.esm.encoder.layer.1.attention.self.query.weight', 'base_model.model.esm.encoder.layer.1.attention.self.query.bias', 'base_model.model.esm.encoder.layer.1.attention.self.key.base_layer.weight', 'base_model.model.esm.encoder.layer.1.attention.self.key.base_layer.bias', 'base_model.model.esm.encoder.layer.1.attention.self.key.lora_A.default.weight', 'base_model.model.esm.encoder.layer.1.attention.self.key.lora_B.default.weight', 'base_model.model.esm.encoder.layer.1.attention.self.value.base_layer.weight', 'base_model.model.esm.encoder.layer.1.attention.self.value.base_layer.bias', 'base_model.model.esm.encoder.layer.1.attention.self.value.lora_A.default.weight', 'base_model.model.esm.encoder.layer.1.attention.self.value.lora_B.default.weight', 'base_model.model.esm.encoder.layer.1.attention.self.rotary_embeddings.inv_freq', 'base_model.model.esm.encoder.layer.1.attention.output.dense.weight', 'base_model.model.esm.encoder.layer.1.attention.output.dense.bias', 'base_model.model.esm.encoder.layer.1.attention.LayerNorm.weight', 'base_model.model.esm.encoder.layer.1.attention.LayerNorm.bias', 'base_model.model.esm.encoder.layer.1.intermediate.dense.weight', 'base_model.model.esm.encoder.layer.1.intermediate.dense.bias', 'base_model.model.esm.encoder.layer.1.output.dense.weight', 'base_model.model.esm.encoder.layer.1.output.dense.bias', 'base_model.model.esm.encoder.layer.1.LayerNorm.weight', 'base_model.model.esm.encoder.layer.1.LayerNorm.bias', 'base_model.model.esm.encoder.layer.2.attention.self.query.weight', 'base_model.model.esm.encoder.layer.2.attention.self.query.bias', 'base_model.model.esm.encoder.layer.2.attention.self.key.base_layer.weight', 'base_model.model.esm.encoder.layer.2.attention.self.key.base_layer.bias', 'base_model.model.esm.encoder.layer.2.attention.self.key.lora_A.default.weight', 'base_model.model.esm.encoder.layer.2.attention.self.key.lora_B.default.weight', 'base_model.model.esm.encoder.layer.2.attention.self.value.base_layer.weight', 'base_model.model.esm.encoder.layer.2.attention.self.value.base_layer.bias', 'base_model.model.esm.encoder.layer.2.attention.self.value.lora_A.default.weight', 'base_model.model.esm.encoder.layer.2.attention.self.value.lora_B.default.weight', 'base_model.model.esm.encoder.layer.2.attention.self.rotary_embeddings.inv_freq', 'base_model.model.esm.encoder.layer.2.attention.output.dense.weight', 'base_model.model.esm.encoder.lay
There were unexpected keys in the checkpoint model loaded: ['esm.contact_head.regression.bias', 'esm.contact_head.regression.weight', 'esm.embeddings.position_embeddings.weight', 'esm.embeddings.word_embeddings.weight', 'esm.encoder.emb_layer_norm_after.bias', 'esm.encoder.emb_layer_norm_after.weight', 'esm.encoder.layer.0.LayerNorm.bias', 'esm.encoder.layer.0.LayerNorm.weight', 'esm.encoder.layer.0.attention.LayerNorm.bias', 'esm.encoder.layer.0.attention.LayerNorm.weight', 'esm.encoder.layer.0.attention.output.dense.bias', 'esm.encoder.layer.0.attention.output.dense.weight', 'esm.encoder.layer.0.attention.self.key.bias', 'esm.encoder.layer.0.attention.self.key.weight', 'esm.encoder.layer.0.attention.self.query.bias', 'esm.encoder.layer.0.attention.self.query.weight', 'esm.encoder.layer.0.attention.self.rotary_embeddings.inv_freq', 'esm.encoder.layer.0.attention.self.value.bias', 'esm.encoder.layer.0.attention.self.value.weight', 'esm.encoder.layer.0.intermediate.dense.bias', 'esm.encoder.layer.0.intermediate.dense.weight', 'esm.encoder.layer.0.output.dense.bias', 'esm.encoder.layer.0.output.dense.weight', 'esm.encoder.layer.1.LayerNorm.bias', 'esm.encoder.layer.1.LayerNorm.weight', 'esm.encoder.layer.1.attention.LayerNorm.bias', 'esm.encoder.layer.1.attention.LayerNorm.weight', 'esm.encoder.layer.1.attention.output.dense.bias', 'esm.encoder.layer.1.attention.output.dense.weight', 'esm.encoder.layer.1.attention.self.key.bias', 'esm.encoder.layer.1.attention.self.key.weight', 'esm.encoder.layer.1.attention.self.query.bias', 'esm.encoder.layer.1.attention.self.query.weight', 'esm.encoder.layer.1.attention.self.rotary_embeddings.inv_freq', 'esm.encoder.layer.1.attention.self.value.bias', 'esm.encoder.layer.1.attention.self.value.weight', 'esm.encoder.layer.1.intermediate.dense.bias', 'esm.encoder.layer.1.intermediate.dense.weight', 'esm.encoder.layer.1.output.dense.bias', 'esm.encoder.layer.1.output.dense.weight', 'esm.encoder.layer.2.LayerNorm.bias', 'esm.encoder.layer.2.LayerNorm.weight', 'esm.encoder.layer.2.attention.LayerNorm.bias', 'esm.encoder.layer.2.attention.LayerNorm.weight', 'esm.encoder.layer.2.attention.output.dense.bias', 'esm.encoder.layer.2.attention.output.dense.weight', 'esm.encoder.layer.2.attention.self.key.bias', 'esm.encoder.layer.2.attention.self.key.weight', 'esm.encoder.layer.2.attention.self.query.bias', 'esm.encoder.layer.2.attention.self.query.weight', 'esm.encoder.layer.2.attention.self.rotary_embeddings.inv_freq', 'esm.encoder.layer.2.attention.self.value.bias', 'esm.encoder.layer.2.attention.self.value.weight', 'esm.encoder.layer.2.intermediate.dense.bias', 'esm.encoder.layer.2.intermediate.dense.weight', 'esm.encoder.layer.2.output.dense.bias', 'esm.encoder.layer.2.output.dense.weight', 'esm.encoder.layer.3.LayerNorm.bias', 'esm.encoder.layer.3.LayerNorm.weight', 'esm.encoder.layer.3.attention.LayerNorm.bias', 'esm.encoder.layer.3.attention.LayerNorm.weight', 'esm.encoder.layer.3.attention.output.dense.bias', 'esm.encoder.layer.3.attention.output.dense.weight', 'esm.encoder.layer.3.attention.self.key.bias', 'esm.encoder.layer.3.attention.self.key.weight', 'esm.encoder.layer.3.attention.self.query.bias', 'esm.encoder.layer.3.attention.self.query.weight', 'esm.encoder.layer.3.attention.self.rotary_embeddings.inv_freq', 'esm.encoder.layer.3.attention.self.value.bias', 'esm.encoder.layer.3.attention.self.value.weight', 'esm.encoder.layer.3.intermediate.dense.bias', 'esm.encoder.layer.3.intermediate.dense.weight', 'esm.encoder.layer.3.output.dense.bias', 'esm.encoder.layer.3.output.dense.weight', 'esm.encoder.layer.4.LayerNorm.bias', 'esm.encoder.layer.4.LayerNorm.weight', 'esm.encoder.layer.4.attention.LayerNorm.bias', 'esm.encoder.layer.4.attention.LayerNorm.weight', 'esm.encoder.layer.4.attention.output.dense.bias', 'esm.encoder.layer.4.attention.output.dense.weight', 'esm.encoder.layer.4.attention.self.key.bias', 'esm.encoder.layer.4.attention.self.key.weight', 'esm.encoder.layer.4.attention.self.query.bias', 'esm.encoder.layer.4.attention.self.query.weight', 'esm.encoder.layer.4.attention.s
Traceback (most recent call last):
  File "/home/sdowell/scratch/Thesis/BenchmarkingFinetuning/finetuneESM2_ProGen2_LoRA.py", line 588, in <module>
    main()
    ~~~~^^
  File "/home/sdowell/scratch/Thesis/BenchmarkingFinetuning/finetuneESM2_ProGen2_LoRA.py", line 561, in main
    train_result = trainer.train(resume_from_checkpoint=checkpoint)
  File "/home/sdowell/miniconda3/envs/thesis/lib/python3.13/site-packages/transformers/trainer.py", line 2241, in train
    return inner_training_loop(
        args=args,
    ...<2 lines>...
        ignore_keys_for_eval=ignore_keys_for_eval,
    )
  File "/home/sdowell/miniconda3/envs/thesis/lib/python3.13/site-packages/transformers/trainer.py", line 2396, in _inner_training_loop
    self._load_optimizer_and_scheduler(resume_from_checkpoint)
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/sdowell/miniconda3/envs/thesis/lib/python3.13/site-packages/transformers/trainer.py", line 3422, in _load_optimizer_and_scheduler
    self.optimizer.load_state_dict(
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        torch.load(os.path.join(checkpoint, OPTIMIZER_NAME), map_location=map_location)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/sdowell/miniconda3/envs/thesis/lib/python3.13/site-packages/accelerate/optimizer.py", line 106, in load_state_dict
    self.optimizer.load_state_dict(state_dict)
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^
  File "/home/sdowell/miniconda3/envs/thesis/lib/python3.13/site-packages/torch/_compile.py", line 32, in inner
    return disable_fn(*args, **kwargs)
  File "/home/sdowell/miniconda3/envs/thesis/lib/python3.13/site-packages/torch/_dynamo/eval_frame.py", line 745, in _fn
    return fn(*args, **kwargs)
  File "/home/sdowell/miniconda3/envs/thesis/lib/python3.13/site-packages/torch/optim/optimizer.py", line 880, in load_state_dict
    raise ValueError(
    ...<2 lines>...
    )
ValueError: loaded state dict contains a parameter group that doesn't match the size of optimizer's group
