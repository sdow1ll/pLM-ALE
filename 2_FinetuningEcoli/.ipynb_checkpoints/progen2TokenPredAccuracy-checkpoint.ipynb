{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d51af28c-45de-4cff-a3de-afced398120c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sequences: 469it [00:13, 34.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 469 sequences.\n",
      "Pretrained model Overall Next Token Prediction Accuracy: 0.6015 (191120/317715)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sequences: 469it [00:14, 32.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 469 sequences.\n",
      "Finetuned model Overall Next Token Prediction Accuracy: 0.9952 (316205/317715)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from Bio import SeqIO\n",
    "from tqdm import tqdm\n",
    "\n",
    "def compute_next_token_prediction_accuracy(model, tokenizer, sequence, device=torch.device(\"cpu\")):\n",
    "    \"\"\"\n",
    "    Computes next token prediction accuracy for a causal language model.\n",
    "    \n",
    "    For a given sequence, this function computes the probability distribution for the next token\n",
    "    at every position (except the first token, which has no preceding context) and compares the \n",
    "    predicted token (argmax of the model's logits) with the actual token.\n",
    "    \n",
    "    Args:\n",
    "        model: The autoregressive language model (e.g., progen2).\n",
    "        tokenizer: The corresponding tokenizer.\n",
    "        sequence: A string representing the protein (or other) sequence.\n",
    "        device: Torch device on which to run computations.\n",
    "    \n",
    "    Returns:\n",
    "        A tuple (correct, total) where:\n",
    "          - correct: number of next-token predictions that exactly match the target token.\n",
    "          - total: total number of predictions made (i.e., sequence length minus one).\n",
    "    \"\"\"\n",
    "    # Tokenize the sequence.\n",
    "    encoded = tokenizer(sequence, return_tensors=\"pt\")\n",
    "    input_ids = encoded.input_ids.to(device)\n",
    "    attention_mask = encoded.attention_mask.to(device)\n",
    "    \n",
    "    # Forward pass through the model.\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits  # shape: [batch, sequence_length, vocab_size]\n",
    "    \n",
    "    # Shift logits to compare predictions at positions 0 ... (L-2) with target tokens at 1 ... (L-1)\n",
    "    logits_shifted = logits[:, :-1, :]\n",
    "    predictions = torch.argmax(logits_shifted, dim=-1)\n",
    "    targets = input_ids[:, 1:]\n",
    "    \n",
    "    # Count correct predictions.\n",
    "    correct = (predictions == targets).sum().item()\n",
    "    total = targets.numel()  # Total number of predictions\n",
    "    \n",
    "    return correct, total\n",
    "\n",
    "# ----- Load model and tokenizer -----\n",
    "base_model_name = \"hugohrban/progen2-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name, trust_remote_code=True)\n",
    "model_pretrained = AutoModelForCausalLM.from_pretrained(base_model_name, trust_remote_code=True)\n",
    "\n",
    "adapter_checkpoint = \"/home/sdowell/scratch/Thesis/BenchmarkingFinetuning/runs/progen2_151m_ecoli_finetuning_1\"\n",
    "model_with_adapter = AutoModelForCausalLM.from_pretrained(base_model_name, trust_remote_code=True)\n",
    "model_finetuned = PeftModel.from_pretrained(model_with_adapter, adapter_checkpoint)\n",
    "\n",
    "# ----- Set device -----\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ----- Process the entire test set from a FASTA file -----\n",
    "fasta_file = \"/home/sdowell/scratch/Thesis/BenchmarkingFinetuning/dataset_splits/finetuning_dataset/test.fasta\"\n",
    "\n",
    "# Process pretrained model.\n",
    "total_correct = 0\n",
    "total_predictions = 0\n",
    "n_sequences = 0\n",
    "\n",
    "for record in tqdm(SeqIO.parse(fasta_file, \"fasta\"), desc=\"Processing sequences\"):\n",
    "    seq = str(record.seq).strip()\n",
    "    if not seq:\n",
    "        continue\n",
    "    correct, predictions = compute_next_token_prediction_accuracy(model_pretrained, tokenizer, seq, device)\n",
    "    total_correct += correct\n",
    "    total_predictions += predictions\n",
    "    n_sequences += 1\n",
    "\n",
    "overall_accuracy = total_correct / total_predictions if total_predictions > 0 else 0.0\n",
    "print(f\"\\nProcessed {n_sequences} sequences.\")\n",
    "print(f\"Pretrained model Overall Next Token Prediction Accuracy: {overall_accuracy:.4f} ({total_correct}/{total_predictions})\")\n",
    "\n",
    "# Reinitialize the counters for the finetuned model.\n",
    "total_correct = 0\n",
    "total_predictions = 0\n",
    "n_sequences = 0\n",
    "\n",
    "for record in tqdm(SeqIO.parse(fasta_file, \"fasta\"), desc=\"Processing sequences\"):\n",
    "    seq = str(record.seq).strip()\n",
    "    if not seq:\n",
    "        continue\n",
    "    correct, predictions = compute_next_token_prediction_accuracy(model_finetuned, tokenizer, seq, device)\n",
    "    total_correct += correct\n",
    "    total_predictions += predictions\n",
    "    n_sequences += 1\n",
    "\n",
    "overall_accuracy = total_correct / total_predictions if total_predictions > 0 else 0.0\n",
    "print(f\"\\nProcessed {n_sequences} sequences.\")\n",
    "print(f\"Finetuned model Overall Next Token Prediction Accuracy: {overall_accuracy:.4f} ({total_correct}/{total_predictions})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34a4c05-0874-4d9f-a84e-9ad49f4fb93c",
   "metadata": {},
   "source": [
    "# ProGen2 Pre-trained Recall, Precision, F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b748d02a-f275-4c63-8f4c-6977a68a38e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sequences: 469it [00:13, 35.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2  0.00000000 0.00000000 0.00000000         0\n",
      "           A  0.52735066 0.61495980 0.56779565     28610\n",
      "           C  0.99314317 0.78820200 0.87888350      4594\n",
      "           D  0.51745205 0.59601028 0.55395990     16342\n",
      "           E  0.53813590 0.68990893 0.60464366     21742\n",
      "           F  0.71216475 0.62726736 0.66702552     11853\n",
      "           G  0.65625135 0.69199835 0.67365096     21883\n",
      "           H  0.72688172 0.46510714 0.56725006      5087\n",
      "           I  0.88326271 0.54855263 0.67678571     15200\n",
      "           K  0.49651198 0.55596526 0.52455940     20611\n",
      "           L  0.45155999 0.80028749 0.57735119     31305\n",
      "           M  0.79707856 0.48815280 0.60548808      8272\n",
      "           N  0.79842715 0.33700210 0.47395577     11448\n",
      "           P  0.67230225 0.73629679 0.70284584     14960\n",
      "           Q  0.71782865 0.33721688 0.45886918     12274\n",
      "           R  0.67363936 0.61669400 0.64391012     22559\n",
      "           S  0.54737634 0.39222848 0.45699337     16702\n",
      "           T  0.72942531 0.52512578 0.61064079     16895\n",
      "           V  0.68400260 0.60174253 0.64024112     21004\n",
      "           W  0.91417227 0.54378634 0.68193210      5504\n",
      "           X  0.71428571 0.62500000 0.66666667        16\n",
      "           Y  0.70977095 0.67661692 0.69279751     10854\n",
      "\n",
      "    accuracy                      0.60154541    317715\n",
      "   macro avg  0.65731925 0.55718736 0.58755664    317715\n",
      "weighted avg  0.63729963 0.60154541 0.60108987    317715\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def compute_token_level_metrics(model, tokenizer, sequence, device=torch.device(\"cpu\")):\n",
    "    encoded = tokenizer(sequence, return_tensors=\"pt\")\n",
    "    input_ids = encoded.input_ids.to(device)\n",
    "    attention_mask = encoded.attention_mask.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "\n",
    "    logits_shifted = logits[:, :-1, :]\n",
    "    predictions = torch.argmax(logits_shifted, dim=-1)\n",
    "    targets = input_ids[:, 1:]\n",
    "\n",
    "    preds = predictions.view(-1).tolist()\n",
    "    trues = targets.view(-1).tolist()\n",
    "\n",
    "    return trues, preds\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "all_trues = []\n",
    "all_preds = []\n",
    "\n",
    "for record in tqdm(SeqIO.parse(fasta_file, \"fasta\"), desc=\"Processing sequences\"):\n",
    "    seq = str(record.seq).strip()\n",
    "    if not seq:\n",
    "        continue\n",
    "    trues, preds = compute_token_level_metrics(model_pretrained, tokenizer, seq, device)\n",
    "    all_trues.extend(trues)\n",
    "    all_preds.extend(preds)\n",
    "\n",
    "# Convert token IDs back to tokens (optional but makes report readable)\n",
    "id2token = tokenizer.convert_ids_to_tokens\n",
    "\n",
    "true_tokens = [id2token(t) for t in all_trues]\n",
    "pred_tokens = [id2token(p) for p in all_preds]\n",
    "\n",
    "print(classification_report(true_tokens, pred_tokens, zero_division=0, digits=10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc51981-d89e-4f98-8a61-25673a0a2889",
   "metadata": {},
   "source": [
    "# ProGen2 fine-tuned Recall, Precisio, F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e472cbb3-2420-4028-bc07-4a29c9910440",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sequences: 469it [00:13, 35.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A  0.99494756 0.99804264 0.99649270     28610\n",
      "           C  0.99912358 0.99259904 0.99585062      4594\n",
      "           D  0.99485609 0.99412557 0.99449070     16342\n",
      "           E  0.99763396 0.98905344 0.99332517     21742\n",
      "           F  0.99847999 0.99755336 0.99801646     11853\n",
      "           G  0.98684270 0.99739524 0.99209091     21883\n",
      "           H  0.99448493 0.99252998 0.99350649      5087\n",
      "           I  0.99519674 0.99506579 0.99513126     15200\n",
      "           K  0.99767386 0.99883557 0.99825438     20611\n",
      "           L  0.99773206 0.99776394 0.99774800     31305\n",
      "           M  0.99564797 0.99564797 0.99564797      8272\n",
      "           N  0.99339323 0.98506289 0.98921053     11448\n",
      "           P  0.99599439 0.99725936 0.99662647     14960\n",
      "           Q  0.99431357 0.99722992 0.99576961     12274\n",
      "           R  0.99658658 0.99654240 0.99656449     22559\n",
      "           S  0.99021713 0.99389295 0.99205163     16702\n",
      "           T  0.99360265 0.99283812 0.99322024     16895\n",
      "           V  0.99675634 0.99485812 0.99580633     21004\n",
      "           W  0.99655735 0.99927326 0.99791345      5504\n",
      "           X  1.00000000 0.56250000 0.72000000        16\n",
      "           Y  0.99814523 0.99161599 0.99486990     10854\n",
      "\n",
      "    accuracy                      0.99524731    317715\n",
      "   macro avg  0.99562790 0.97427074 0.98202797    317715\n",
      "weighted avg  0.99525654 0.99524731 0.99524384    317715\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "all_trues = []\n",
    "all_preds = []\n",
    "\n",
    "for record in tqdm(SeqIO.parse(fasta_file, \"fasta\"), desc=\"Processing sequences\"):\n",
    "    seq = str(record.seq).strip()\n",
    "    if not seq:\n",
    "        continue\n",
    "    trues, preds = compute_token_level_metrics(model_finetuned, tokenizer, seq, device)\n",
    "    all_trues.extend(trues)\n",
    "    all_preds.extend(preds)\n",
    "\n",
    "# Convert token IDs back to tokens (optional but makes report readable)\n",
    "id2token = tokenizer.convert_ids_to_tokens\n",
    "\n",
    "true_tokens = [id2token(t) for t in all_trues]\n",
    "pred_tokens = [id2token(p) for p in all_preds]\n",
    "\n",
    "print(classification_report(true_tokens, pred_tokens, zero_division=0, digits=10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e816bb24-ed72-442c-97dc-5d05e50fa2b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
